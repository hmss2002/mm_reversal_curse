# 8x V100 32GB FP16 è¯„æµ‹æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

`evaluate.py` è„šæœ¬å·²å®Œå…¨æ”¯æŒ 8x V100 32GB FP16 ç¯å¢ƒçš„åˆ†å¸ƒå¼è¯„æµ‹ï¼Œæ— éœ€é¢å¤–ä¿®æ”¹ã€‚

## ğŸ” åŠŸèƒ½æ£€æŸ¥ç»“æœ

### å·²åˆ é™¤é‡å¤æ–‡ä»¶
- âœ… `evaluate_old.py` - ä¸ `evaluate.py` å®Œå…¨ç›¸åŒï¼Œå·²åˆ é™¤

### evaluate.py åŠŸèƒ½ç‰¹æ€§

#### âœ… å·²æ”¯æŒçš„åŠŸèƒ½ï¼š
1. **åˆ†å¸ƒå¼è¯„æµ‹** - ä½¿ç”¨ `--mode distributed` + `torchrun`
2. **FP16ç²¾åº¦** - é»˜è®¤ä½¿ç”¨ `torch_dtype=torch.float16`
3. **4-bité‡åŒ–** - ä½¿ç”¨ `--use_4bit` è¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜
4. **æ¨¡å‹å¹¶è¡Œ** - é€šè¿‡ `device_map` è‡ªåŠ¨å¤„ç†32Bæ¨¡å‹
5. **æ•°æ®å¹¶è¡Œ** - 8Bæ¨¡å‹å¯åœ¨8å¡ä¸Šåˆ†å¸ƒè¯„æµ‹
6. **4ç§è¯„æµ‹ä»»åŠ¡** - forward, reverse, mcq_i2d, mcq_d2i

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: ä½¿ç”¨ torchrunï¼ˆæ¨èï¼‰

#### è¯„æµ‹ 8B æ¨¡å‹ï¼ˆæ•°æ®å¹¶è¡Œï¼‰
```bash
cd /work/mm_reversal_curse
source .venv/bin/activate

# è¯„æµ‹æ‰€æœ‰ä»»åŠ¡
torchrun --nproc_per_node=8 scripts/evaluate.py \
    --model_path outputs/8faces_forward/best \
    --base_model /work/models/qwen/Qwen3-VL-8B-Instruct \
    --data_dir data/8faces \
    --task all \
    --mode distributed \
    --save_examples 10

# åªè¯„æµ‹ forward ä»»åŠ¡
torchrun --nproc_per_node=8 scripts/evaluate.py \
    --model_path outputs/8faces_forward/best \
    --data_file data/8faces/forward_test.jsonl \
    --task forward \
    --mode distributed
```

#### è¯„æµ‹ 32B æ¨¡å‹ï¼ˆæ¨¡å‹å¹¶è¡Œ + 4bitï¼‰
```bash
# 32Bæ¨¡å‹å»ºè®®ä½¿ç”¨4bité‡åŒ–å’Œauto device_map
torchrun --nproc_per_node=8 scripts/evaluate.py \
    --model_path outputs/4faces_32b_test_forward/best \
    --base_model /work/models/qwen/Qwen3-VL-32B-Instruct \
    --data_dir data/4faces \
    --task all \
    --mode distributed \
    --use_4bit \
    --device_map auto \
    --save_examples 10
```

### æ–¹æ³•2: ä½¿ç”¨ä¾¿æ·è„šæœ¬

```bash
# 8Bæ¨¡å‹è¯„æµ‹
bash scripts/run_eval_8v100.sh \
    --model_path outputs/8faces_forward/best \
    --data_dir data/8faces

# 32Bæ¨¡å‹è¯„æµ‹ï¼ˆè‡ªåŠ¨ä½¿ç”¨æ¨¡å‹å¹¶è¡Œï¼‰
bash scripts/run_eval_8v100.sh \
    --model_path outputs/4faces_32b_test_forward/best \
    --base_model /work/models/qwen/Qwen3-VL-32B-Instruct \
    --data_dir data/4faces \
    --model_parallel
```

### æ–¹æ³•3: å•GPUè¯„æµ‹ï¼ˆè°ƒè¯•ç”¨ï¼‰

```bash
python3 scripts/evaluate.py \
    --model_path outputs/8faces_forward/best \
    --data_dir data/8faces \
    --task forward \
    --max_samples 10
```

## ğŸ“Š å‚æ•°è¯´æ˜

### å¿…éœ€å‚æ•°
- `--model_path`: LoRA adapterè·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™è¯„æµ‹base modelï¼‰
- `--data_dir`: æ•°æ®ç›®å½•ï¼ˆtask=allæ—¶ï¼‰
- `--data_file`: æ•°æ®æ–‡ä»¶ï¼ˆå•ä»»åŠ¡æ—¶ï¼‰

### é‡è¦å‚æ•°
- `--mode`: è¯„æµ‹æ¨¡å¼
  - `single`: å•GPUï¼ˆé»˜è®¤ï¼‰
  - `distributed`: å¤šGPUåˆ†å¸ƒå¼
- `--task`: è¯„æµ‹ä»»åŠ¡
  - `forward`: å›¾åƒâ†’æè¿°
  - `reverse`: æè¿°+å›¾åƒâ†’æ­£ç¡®/é”™è¯¯
  - `mcq_i2d`: å›¾åƒâ†’é€‰æ‹©æè¿°
  - `mcq_d2i`: æè¿°â†’é€‰æ‹©å›¾åƒ
  - `all`: æ‰€æœ‰ä»»åŠ¡ï¼ˆé»˜è®¤ï¼‰
- `--base_model`: åŸºç¡€æ¨¡å‹è·¯å¾„
  - é»˜è®¤: `/work/models/qwen/Qwen3-VL-8B-Instruct`
  - 32B: `/work/models/qwen/Qwen3-VL-32B-Instruct`

### ä¼˜åŒ–å‚æ•°
- `--use_4bit`: ä½¿ç”¨4-bité‡åŒ–ï¼ˆ32Bæ¨¡å‹æ¨èï¼‰
- `--device_map`: è®¾å¤‡æ˜ å°„ç­–ç•¥
  - `cuda`: å•å¡ï¼ˆé»˜è®¤ï¼‰
  - `auto`: è‡ªåŠ¨å¤šå¡åˆ†å¸ƒï¼ˆ32Bæ¨èï¼‰
- `--save_examples`: ä¿å­˜æ ·ä¾‹æ•°é‡ï¼ˆ-1=å…¨éƒ¨ï¼Œ0=ä¸ä¿å­˜ï¼Œé»˜è®¤5ï¼‰
- `--max_samples`: é™åˆ¶æ ·æœ¬æ•°é‡ï¼ˆè°ƒè¯•ç”¨ï¼‰

## ğŸ’¾ å†…å­˜ä¼˜åŒ–å»ºè®®

### 8B æ¨¡å‹ï¼ˆå•å¡ ~16GBï¼‰
```bash
# V100 32GB å®Œå…¨å¤Ÿç”¨ï¼Œä½¿ç”¨FP16å³å¯
torchrun --nproc_per_node=8 scripts/evaluate.py \
    --model_path <path> \
    --data_dir <dir> \
    --mode distributed
```

### 32B æ¨¡å‹ï¼ˆå•å¡ ~60GBï¼Œéœ€è¦è·¨å¡ï¼‰
```bash
# æ–¹æ¡ˆ1: 4-bité‡åŒ– + auto device_mapï¼ˆæ¨èï¼‰
torchrun --nproc_per_node=8 scripts/evaluate.py \
    --model_path <path> \
    --base_model /work/models/qwen/Qwen3-VL-32B-Instruct \
    --data_dir <dir> \
    --mode distributed \
    --use_4bit \
    --device_map auto

# æ–¹æ¡ˆ2: FP16 + auto device_mapï¼ˆæ˜¾å­˜å……è¶³æ—¶ï¼‰
torchrun --nproc_per_node=8 scripts/evaluate.py \
    --model_path <path> \
    --base_model /work/models/qwen/Qwen3-VL-32B-Instruct \
    --data_dir <dir> \
    --mode distributed \
    --device_map auto
```

## ğŸ“ è¾“å‡ºç»“æ„

```
outputs/<model_name>/
â”œâ”€â”€ eval_results_v3.json         # è¯„æµ‹ç»“æœæ±‡æ€»
â”‚   â”œâ”€â”€ timestamp               # è¯„æµ‹æ—¶é—´
â”‚   â”œâ”€â”€ forward                 # Forwardä»»åŠ¡ç»“æœ
â”‚   â”‚   â”œâ”€â”€ accuracy
â”‚   â”‚   â”œâ”€â”€ correct
â”‚   â”‚   â”œâ”€â”€ total
â”‚   â”‚   â””â”€â”€ examples (å¯é€‰)
â”‚   â”œâ”€â”€ reverse                 # Reverseä»»åŠ¡ç»“æœ
â”‚   â”‚   â”œâ”€â”€ accuracy
â”‚   â”‚   â”œâ”€â”€ tpr                 # True Positive Rate
â”‚   â”‚   â”œâ”€â”€ fpr                 # False Positive Rate
â”‚   â”‚   â”œâ”€â”€ separation          # TPR - FPR
â”‚   â”‚   â””â”€â”€ examples (å¯é€‰)
â”‚   â”œâ”€â”€ mcq_i2d                 # MCQ I2Dç»“æœ
â”‚   â””â”€â”€ mcq_d2i                 # MCQ D2Iç»“æœ
```

## ğŸ”§ troubleshooting

### é—®é¢˜1: CUDA OOM (æ˜¾å­˜æº¢å‡º)
```bash
# è§£å†³æ–¹æ¡ˆ1: ä½¿ç”¨4bité‡åŒ–
--use_4bit

# è§£å†³æ–¹æ¡ˆ2: å‡å°‘æ ·æœ¬æ•°é‡ï¼ˆè°ƒè¯•ï¼‰
--max_samples 100

# è§£å†³æ–¹æ¡ˆ3: ä½¿ç”¨auto device_map
--device_map auto
```

### é—®é¢˜2: åˆ†å¸ƒå¼åˆå§‹åŒ–å¤±è´¥
```bash
# ç¡®ä¿ä½¿ç”¨ torchrun è€Œä¸æ˜¯ python
torchrun --nproc_per_node=8 scripts/evaluate.py ...

# æ£€æŸ¥GPUæ•°é‡
nvidia-smi --list-gpus
```

### é—®é¢˜3: æ¨¡å‹åŠ è½½æ…¢
```bash
# æ­£å¸¸ç°è±¡ï¼Œ32Bæ¨¡å‹åŠ è½½éœ€è¦å‡ åˆ†é’Ÿ
# å¯ä»¥æ·»åŠ  --max_samples 10 å¿«é€Ÿæµ‹è¯•
```

## âœ¨ æœ€ä½³å®è·µ

1. **8Bæ¨¡å‹**: ç›´æ¥ä½¿ç”¨8å¡æ•°æ®å¹¶è¡Œï¼ŒFP16ç²¾åº¦
   ```bash
   torchrun --nproc_per_node=8 scripts/evaluate.py \
       --model_path outputs/8faces_forward/best \
       --data_dir data/8faces \
       --mode distributed
   ```

2. **32Bæ¨¡å‹**: ä½¿ç”¨4bité‡åŒ– + auto device_map
   ```bash
   torchrun --nproc_per_node=8 scripts/evaluate.py \
       --model_path outputs/4faces_32b_test_forward/best \
       --base_model /work/models/qwen/Qwen3-VL-32B-Instruct \
       --data_dir data/4faces \
       --mode distributed \
       --use_4bit \
       --device_map auto
   ```

3. **å¿«é€Ÿæµ‹è¯•**: ä½¿ç”¨å•GPU + max_samples
   ```bash
   python3 scripts/evaluate.py \
       --model_path outputs/8faces_forward/best \
       --data_file data/8faces/forward_test.jsonl \
       --task forward \
       --max_samples 10
   ```

## ğŸ“ æ€»ç»“

- âœ… **evaluate.py å·²å®Œå…¨æ”¯æŒ 8x V100 32GB FP16 ç¯å¢ƒ**
- âœ… **æ— éœ€ä¿®æ”¹ä»£ç ï¼Œä½¿ç”¨ç°æœ‰å‚æ•°å³å¯**
- âœ… **æ”¯æŒ8Bæ¨¡å‹æ•°æ®å¹¶è¡Œ å’Œ 32Bæ¨¡å‹æ¨¡å‹å¹¶è¡Œ**
- âœ… **æä¾›ä¾¿æ·è„šæœ¬ run_eval_8v100.sh**
- âœ… **åˆ é™¤äº†é‡å¤çš„ evaluate_old.py**

ä½¿ç”¨ `torchrun` + `--mode distributed` å³å¯å……åˆ†åˆ©ç”¨8å¡V100èµ„æºï¼
